{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91626\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\91626\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>act_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-13</td>\n",
       "      <td>Finchinator</td>\n",
       "      <td>Volcarona is one of the strongest win conditio...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-14</td>\n",
       "      <td>Shaymin</td>\n",
       "      <td>this is the quietest opening to a OU suspect t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>serotine</td>\n",
       "      <td>Easy echo above, Volcarona is just unbelievabl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>coralreaper</td>\n",
       "      <td>BAN. Volcarona might not be super broken compa...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>daddybuzzwole</td>\n",
       "      <td>plot twist of the century: i actually don't ha...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        user_id  \\\n",
       "0 2024-04-13    Finchinator   \n",
       "1 2024-04-14        Shaymin   \n",
       "2 2024-04-15       serotine   \n",
       "3 2024-04-15    coralreaper   \n",
       "4 2024-04-15  daddybuzzwole   \n",
       "\n",
       "                                                text act_sentiment  \n",
       "0  Volcarona is one of the strongest win conditio...           pos  \n",
       "1  this is the quietest opening to a OU suspect t...           pos  \n",
       "2  Easy echo above, Volcarona is just unbelievabl...           pos  \n",
       "3  BAN. Volcarona might not be super broken compa...           pos  \n",
       "4  plot twist of the century: i actually don't ha...           neg  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"volc_suspect.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91626\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one strongest win condition history modern overused rising prominence debut generation bw remaining one better set option across last thireteen year losing hidden power gaining heavy duty boot reshaped last generation terastallization perhaps biggest impact presence ever generation controversial quickban earlier generation reintroduced flagship metagame hope would stay afloat time around however infamous quiver dancer frequently dubbed match moth controversial presence metagame',\n",
       " 'quietest opening ou suspect test thread ever seen lmao anyways ban guy annoying shit fiery dance trolliest move ever created exist rng mu fish cheese mon meta gen already wide threat list giving option stupid deal way reliably beat volcs set unless u blissey clod troll use besides hard stall need defensive utility v kyurem kyurem check bulky set take spec draco u cannot seriously think counter lol look definition plz defensive utility flame body also coincedentally b rng nonsense end mon arsenal cheese even get started fiery dance boost even storm zone say offensive mon cheesy get nerve mean cmon lmfaoooo thats offense apologist idt u guy understand cringe offense mon make sz mad lmfao happened pheremosa looooooool mon staying tier fear need start payin finch ngl believe claim defensive value tier given v iron valiant run sd liquidation anyways main defensive value inherently rng even think mon rilla much tier without always plenty option v grass spam especially non rng one worst thing cant even figure set based team comp info set mon let alone figuring lmaooo fishing burn fishing autowin mu fishing boost mon genuinely fun competitive balanced imo u couldnt tell im getting reqs voting ban altho suspicion get banned ima ig last thing u insane people flamed council qb dlc genuinely guy never touch tiering position sit say guy dlc gave answer try bro long gonna take people realize learn gen pokemon answer u either run blissey clod risk loss set thats oh combination lmfao fantasy land yall live swear whatever fuck mon dlc clearly clearly fucking effect dlc guy still thinggggggggggggg win easily ur trolling lolll literally yall saying qb dlc warranted need issue apology cu opinion even calling opinion giving bit much credit lmao absurd based reality historical evidence']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "thoughts = df['text']\n",
    "corpus=[]\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(thoughts[i]))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    stop_words=set(stopwords.words('English'))\n",
    "    more_words=['like','volcarona','volc','tera']\n",
    "    stop_words.update(more_words)\n",
    "    review = [lemma.lemmatize(word) for word in review if word not in stop_words]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mon</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>check</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>broken</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  frequency\n",
       "0    team        311\n",
       "1     mon        297\n",
       "2   check        287\n",
       "3     set        271\n",
       "4  broken        258"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list = [word for line in corpus for word in line.split()]\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "word_counts = Counter(words_list).most_common(50)\n",
    "words_df = pd.DataFrame(word_counts)\n",
    "words_df.columns = ['word', 'frequency']\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>act_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-13</td>\n",
       "      <td>Finchinator</td>\n",
       "      <td>one strongest win condition history modern ove...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-14</td>\n",
       "      <td>Shaymin</td>\n",
       "      <td>quietest opening ou suspect test thread ever s...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>serotine</td>\n",
       "      <td>easy echo unbelievably hard account team build...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>coralreaper</td>\n",
       "      <td>ban might super broken compared lot maniac use...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>daddybuzzwole</td>\n",
       "      <td>plot twist century actually strong feeling tow...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        user_id  \\\n",
       "0 2024-04-13    Finchinator   \n",
       "1 2024-04-14        Shaymin   \n",
       "2 2024-04-15       serotine   \n",
       "3 2024-04-15    coralreaper   \n",
       "4 2024-04-15  daddybuzzwole   \n",
       "\n",
       "                                                text act_sentiment  \n",
       "0  one strongest win condition history modern ove...           pos  \n",
       "1  quietest opening ou suspect test thread ever s...           pos  \n",
       "2  easy echo unbelievably hard account team build...           pos  \n",
       "3  ban might super broken compared lot maniac use...           pos  \n",
       "4  plot twist century actually strong feeling tow...           neg  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = corpus\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text vectorisers ##\n",
    "\n",
    "\n",
    "## bag or words ##\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "\n",
    "## tf idf ##\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tif = TfidfVectorizer()\n",
    "X1 = tif.fit_transform(corpus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=pd.get_dummies(df['act_sentiment'])\n",
    "y=y.iloc[:,1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 41)\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size = 0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction models #\n",
    "\n",
    "\n",
    "# PSA (Polarity Score Analysis) #\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "ps = lambda x : sid.polarity_scores(x)\n",
    "sentiment_scores = df.text.apply(ps)\n",
    "sentiment_df = pd.DataFrame(data = list(sentiment_scores))\n",
    "labelize = lambda x : 'neu' if x==0 else('pos' if x>0 else 'neg')\n",
    "sentiment_df['label_psa'] = sentiment_df.compound.apply(labelize)\n",
    "\n",
    "\n",
    "# VSA (Vader Sentiment Analyser) #\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "def sentiment_Vader(text):\n",
    "    over_all_polarity = sid.polarity_scores(text)\n",
    "    if over_all_polarity['compound'] >= 0.05:\n",
    "        return \"pos\"\n",
    "    elif over_all_polarity['compound'] <= -0.05:\n",
    "        return \"neg\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "vad = pd.DataFrame(data = list(df['text'].apply(lambda x: sentiment_Vader(x))))\n",
    "\n",
    "\n",
    "\n",
    "# naive bayes #\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB().fit(X_train, y_train)\n",
    "nb_model_1 = MultinomialNB().fit(X1_train, y_train)\n",
    "\n",
    "\n",
    "# svm #\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf').fit(X_train, y_train)\n",
    "clf_1 = svm.SVC(kernel='rbf').fit(X1_train, y_train)\n",
    "\n",
    "\n",
    "# log regr #\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C = 10, solver = 'liblinear').fit(X_train,y_train)\n",
    "LR_1 = LogisticRegression(C = 10, solver = 'liblinear').fit(X1_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>act_sentiment</th>\n",
       "      <th>PSA_label</th>\n",
       "      <th>VSA_label</th>\n",
       "      <th>BoW_Nb_label</th>\n",
       "      <th>BoW_SVM_label</th>\n",
       "      <th>BoW_LR_label</th>\n",
       "      <th>TfIdf_Nb_label</th>\n",
       "      <th>TfIdf_SVM_label</th>\n",
       "      <th>Tfidf_LR_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-13</td>\n",
       "      <td>Finchinator</td>\n",
       "      <td>one strongest win condition history modern ove...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-14</td>\n",
       "      <td>Shaymin</td>\n",
       "      <td>quietest opening ou suspect test thread ever s...</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>serotine</td>\n",
       "      <td>easy echo unbelievably hard account team build...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>coralreaper</td>\n",
       "      <td>ban might super broken compared lot maniac use...</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>daddybuzzwole</td>\n",
       "      <td>plot twist century actually strong feeling tow...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>earthflax</td>\n",
       "      <td>people complaining reason ever since released ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>gummyrowlets</td>\n",
       "      <td>analysing obviously broken something flutter m...</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        user_id  \\\n",
       "0 2024-04-13    Finchinator   \n",
       "1 2024-04-14        Shaymin   \n",
       "2 2024-04-15       serotine   \n",
       "3 2024-04-15    coralreaper   \n",
       "4 2024-04-15  daddybuzzwole   \n",
       "5 2024-04-15      earthflax   \n",
       "6 2024-04-15   gummyrowlets   \n",
       "\n",
       "                                                text act_sentiment PSA_label  \\\n",
       "0  one strongest win condition history modern ove...           pos       pos   \n",
       "1  quietest opening ou suspect test thread ever s...           pos       neg   \n",
       "2  easy echo unbelievably hard account team build...           pos       pos   \n",
       "3  ban might super broken compared lot maniac use...           pos       neg   \n",
       "4  plot twist century actually strong feeling tow...           neg       neg   \n",
       "5  people complaining reason ever since released ...           pos       neg   \n",
       "6  analysing obviously broken something flutter m...           pos       neg   \n",
       "\n",
       "  VSA_label  BoW_Nb_label  BoW_SVM_label  BoW_LR_label  TfIdf_Nb_label  \\\n",
       "0       pos          True           True          True            True   \n",
       "1       neg          True           True          True            True   \n",
       "2       pos          True           True          True            True   \n",
       "3       neg          True           True          True            True   \n",
       "4       neg         False          False         False           False   \n",
       "5       neg          True           True          True            True   \n",
       "6       neg          True           True          True            True   \n",
       "\n",
       "   TfIdf_SVM_label  Tfidf_LR_label  \n",
       "0             True            True  \n",
       "1             True            True  \n",
       "2             True            True  \n",
       "3             True            True  \n",
       "4            False           False  \n",
       "5             True            True  \n",
       "6             True            True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and outputs for train/test set #\n",
    "\n",
    "yhat_nb = nb_model.predict(X_test)\n",
    "yhat_nb_1 = nb_model_1.predict(X1_test)\n",
    "\n",
    "yhat_clf = clf.predict(X_test)\n",
    "yhat_clf_1 = clf_1.predict(X1_test)\n",
    "\n",
    "yhat_LR = LR.predict(X_test)\n",
    "yhat_LR_1 = LR_1.predict(X1_test)\n",
    "\n",
    "# predictions and outputs for whole dataset #\n",
    "\n",
    "yhat_nb_full = nb_model.predict(X)\n",
    "yhat_nb_1_full = nb_model_1.predict(X1)\n",
    "\n",
    "yhat_clf_full = clf.predict(X)\n",
    "yhat_clf_1_full = clf_1.predict(X1)\n",
    "\n",
    "yhat_LR_full = LR.predict(X)\n",
    "yhat_LR_1_full = LR_1.predict(X1)\n",
    "\n",
    "\n",
    "\n",
    "df['PSA_label'] = sentiment_df['label_psa']\n",
    "df['VSA_label'] = vad\n",
    "\n",
    "\n",
    "df['VSA_label'][48] = 'neg'\n",
    "df['PSA_label'][48] = 'neg'\n",
    "\n",
    "\n",
    "df['BoW_Nb_label'] = yhat_nb_full\n",
    "df['BoW_SVM_label'] = yhat_clf_full\n",
    "df['BoW_LR_label'] = yhat_LR_full\n",
    "df['TfIdf_Nb_label'] = yhat_nb_1_full\n",
    "df['TfIdf_SVM_label'] = yhat_clf_1_full\n",
    "df['Tfidf_LR_label'] = yhat_LR_1_full\n",
    "\n",
    "df[0:7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "scores for BoW , Nb model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.46      0.60      0.52        10\n",
      "        True       0.73      0.61      0.67        18\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.60      0.61      0.59        28\n",
      "weighted avg       0.64      0.61      0.61        28\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "scores for BoW , SVM model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.10      0.18        10\n",
      "        True       0.67      1.00      0.80        18\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.83      0.55      0.49        28\n",
      "weighted avg       0.79      0.68      0.58        28\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "scores for BoW , LR model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.60      0.60        10\n",
      "        True       0.78      0.78      0.78        18\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.69      0.69      0.69        28\n",
      "weighted avg       0.71      0.71      0.71        28\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "scores for TfIdf , Nb model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00        10\n",
      "        True       0.63      0.94      0.76        18\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.31      0.47      0.38        28\n",
      "weighted avg       0.40      0.61      0.49        28\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "scores for TfIdf , SVM model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00        10\n",
      "        True       0.64      1.00      0.78        18\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.32      0.50      0.39        28\n",
      "weighted avg       0.41      0.64      0.50        28\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "scores for TfIdf , LR model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.30      0.38        10\n",
      "        True       0.68      0.83      0.75        18\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.59      0.57      0.56        28\n",
      "weighted avg       0.62      0.64      0.62        28\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for BoW , Nb model : \\n\")\n",
    "print(classification_report(y_test, yhat_nb))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for BoW , SVM model : \\n\")\n",
    "print(classification_report(y_test, yhat_clf))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for BoW , LR model : \\n\")\n",
    "print(classification_report(y_test, yhat_LR))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for TfIdf , Nb model : \\n\")\n",
    "print(classification_report(y_test, yhat_nb_1))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for TfIdf , SVM model : \\n\")\n",
    "print(classification_report(y_test, yhat_clf_1))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for TfIdf , LR model : \\n\")\n",
    "print(classification_report(y_test, yhat_LR_1))\n",
    "print('---------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score for BoW, Naive Bayes model is :  0.5\n",
      "similarity score for BoW, SVM model is :  0.6666666666666666\n",
      "similarity score for BoW, LR model is :  0.6363636363636364\n",
      "similarity score for TfIdf, Naive Bayes model is :  0.6071428571428571\n",
      "similarity score for TfIdf, SVM model is :  0.6428571428571429\n",
      "similarity score for TfIdf, LR model is :  0.6\n"
     ]
    }
   ],
   "source": [
    "## jaccard scores ##\n",
    "from sklearn.metrics import jaccard_score\n",
    "print(\"similarity score for BoW, Naive Bayes model is : \",jaccard_score(y_test, yhat_nb,pos_label=1))\n",
    "print(\"similarity score for BoW, SVM model is : \",jaccard_score(y_test, yhat_clf,pos_label=1))\n",
    "print(\"similarity score for BoW, LR model is : \",jaccard_score(y_test, yhat_LR,pos_label=1))\n",
    "print(\"similarity score for TfIdf, Naive Bayes model is : \",jaccard_score(y_test, yhat_nb_1,pos_label=1))\n",
    "print(\"similarity score for TfIdf, SVM model is : \",jaccard_score(y_test, yhat_clf_1,pos_label=1))\n",
    "print(\"similarity score for TfIdf, LR model is : \",jaccard_score(y_test, yhat_LR_1,pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for a full dataset prediction : \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "scores for PSA model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.40      0.63      0.49        57\n",
      "         pos       0.54      0.32      0.40        79\n",
      "\n",
      "    accuracy                           0.45       136\n",
      "   macro avg       0.47      0.47      0.44       136\n",
      "weighted avg       0.48      0.45      0.44       136\n",
      "\n",
      "\n",
      "Similarity score :  0.25\n",
      "---------------------------------------------------------------------------\n",
      "scores for VSA model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.40      0.63      0.49        57\n",
      "         pos       0.54      0.32      0.40        79\n",
      "\n",
      "    accuracy                           0.45       136\n",
      "   macro avg       0.47      0.47      0.44       136\n",
      "weighted avg       0.48      0.45      0.44       136\n",
      "\n",
      "\n",
      "Similarity score :  0.25\n",
      "---------------------------------------------------------------------------\n",
      "scores for BoW , Nb model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.93      0.91        57\n",
      "        True       0.95      0.91      0.93        79\n",
      "\n",
      "    accuracy                           0.92       136\n",
      "   macro avg       0.92      0.92      0.92       136\n",
      "weighted avg       0.92      0.92      0.92       136\n",
      "\n",
      "\n",
      "Similarity score :  0.8674698795180723\n",
      "---------------------------------------------------------------------------\n",
      "scores for BoW , SVM model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.60      0.75        57\n",
      "        True       0.77      1.00      0.87        79\n",
      "\n",
      "    accuracy                           0.83       136\n",
      "   macro avg       0.89      0.80      0.81       136\n",
      "weighted avg       0.87      0.83      0.82       136\n",
      "\n",
      "\n",
      "Similarity score :  0.7745098039215687\n",
      "---------------------------------------------------------------------------\n",
      "scores for BoW , LR model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.93      0.93        57\n",
      "        True       0.95      0.95      0.95        79\n",
      "\n",
      "    accuracy                           0.94       136\n",
      "   macro avg       0.94      0.94      0.94       136\n",
      "weighted avg       0.94      0.94      0.94       136\n",
      "\n",
      "\n",
      "Similarity score :  0.9036144578313253\n",
      "---------------------------------------------------------------------------\n",
      "scores for TfIdf , Nb model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.63      0.77        57\n",
      "        True       0.79      0.99      0.88        79\n",
      "\n",
      "    accuracy                           0.84       136\n",
      "   macro avg       0.88      0.81      0.82       136\n",
      "weighted avg       0.87      0.84      0.83       136\n",
      "\n",
      "\n",
      "Similarity score :  0.78\n",
      "---------------------------------------------------------------------------\n",
      "scores for TfIdf , SVM model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.82      0.90        57\n",
      "        True       0.89      1.00      0.94        79\n",
      "\n",
      "    accuracy                           0.93       136\n",
      "   macro avg       0.94      0.91      0.92       136\n",
      "weighted avg       0.93      0.93      0.93       136\n",
      "\n",
      "\n",
      "Similarity score :  0.8876404494382022\n",
      "---------------------------------------------------------------------------\n",
      "scores for TfIdf , LR model : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.88      0.91        57\n",
      "        True       0.92      0.96      0.94        79\n",
      "\n",
      "    accuracy                           0.93       136\n",
      "   macro avg       0.93      0.92      0.92       136\n",
      "weighted avg       0.93      0.93      0.93       136\n",
      "\n",
      "\n",
      "Similarity score :  0.8837209302325582\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for a full dataset prediction : \\n\")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for PSA model : \\n\")\n",
    "print(classification_report(df['act_sentiment'], df['PSA_label']))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(df['act_sentiment'], df['PSA_label'], pos_label='pos'))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for VSA model : \\n\")\n",
    "print(classification_report(df['act_sentiment'], df['VSA_label']))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(df['act_sentiment'], df['VSA_label'], pos_label='pos'))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for BoW , Nb model : \\n\")\n",
    "print(classification_report(y, yhat_nb_full))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(y, yhat_nb_full))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for BoW , SVM model : \\n\")\n",
    "print(classification_report(y, yhat_clf_full))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(y, yhat_clf_full))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for BoW , LR model : \\n\")\n",
    "print(classification_report(y, yhat_LR_full))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(y, yhat_LR_full))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for TfIdf , Nb model : \\n\")\n",
    "print(classification_report(y, yhat_nb_1_full))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(y, yhat_nb_1_full))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for TfIdf , SVM model : \\n\")\n",
    "print(classification_report(y, yhat_clf_1_full))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(y, yhat_clf_1_full))\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(\"scores for TfIdf , LR model : \\n\")\n",
    "print(classification_report(y, yhat_LR_1_full))\n",
    "print(\"\\nSimilarity score : \", jaccard_score(y, yhat_LR_1_full))\n",
    "print('---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSA sentiment score (out of 10) for the suspect test is :  3.382352941176471\n",
      "VSA sentiment score (out of 10) for the suspect test is :  3.382352941176471\n",
      "BL sentiment score (out of 10) for the suspect test is :  5.808823529411765\n"
     ]
    }
   ],
   "source": [
    "count_psa = 0\n",
    "for i in range(len(df['PSA_label'])):\n",
    "    if df['PSA_label'][i]=='pos':\n",
    "        count_psa = count_psa + 1\n",
    "psa=0\n",
    "psa = count_psa\n",
    "psa_score = (psa / len(df['PSA_label']) ) * 10\n",
    "print(\"PSA sentiment score (out of 10) for the suspect test is : \", psa_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count_vsa = 0\n",
    "for i in range(len(df['VSA_label'])):\n",
    "    if df['VSA_label'][i]=='pos':\n",
    "        count_vsa = count_vsa + 1\n",
    "v=0\n",
    "v = count_vsa\n",
    "vsa_score = (v / len(df['VSA_label']) ) * 10\n",
    "print(\"VSA sentiment score (out of 10) for the suspect test is : \", vsa_score)\n",
    "\n",
    "\n",
    "count_bl = 0\n",
    "for i in range(len(df['BoW_LR_label'])):\n",
    "    if df['BoW_LR_label'][i]==1:\n",
    "        count_bl = count_bl + 1\n",
    "bl=0\n",
    "bl = count_bl\n",
    "bl_score = (bl / len(df['BoW_LR_label']) ) * 10\n",
    "print(\"BL sentiment score (out of 10) for the suspect test is : \", bl_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sentiment score (out of 10) for the suspect test is :  5.808823529411765\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(df['act_sentiment'])):\n",
    "    if df['act_sentiment'][i]=='pos':\n",
    "        count = count + 1\n",
    "p=0\n",
    "p = count\n",
    "\n",
    "score = (p / len(df['act_sentiment']) ) * 10\n",
    "print(\"Actual sentiment score (out of 10) for the suspect test is : \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND THE WINNER ISSSSS : BAG OF WORDS WITH LOGISTIC REGRESSION \n",
      "TESTING ACCURACY = 71%\n",
      "SAMPLE ACCURACY = 94%\n",
      "ANDDDD THE FINAL SUSPECT SCORE BEINGGGG : 5.8/10 \n"
     ]
    }
   ],
   "source": [
    "print(\"AND THE WINNER ISSSSS : BAG OF WORDS WITH LOGISTIC REGRESSION \")\n",
    "print(\"TESTING ACCURACY = 71%\")\n",
    "print(\"SAMPLE ACCURACY = 94%\")\n",
    "print(\"ANDDDD THE FINAL SUSPECT SCORE BEINGGGG : 5.8/10 \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the actual ban percentage was like 76% majority\n",
      "what the fuck did i do all this for\n"
     ]
    }
   ],
   "source": [
    "print(\"the actual ban percentage was like 76% majority\")\n",
    "print(\"what the fuck did i do all this for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
